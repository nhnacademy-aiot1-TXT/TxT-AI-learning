# TxT-AI-learning
## 구현 모델 : 현재 온도, 습도에 따른 에어컨 ON/OFF 여부 판별 AI 모델

## 구현 방식 : 머신러닝의 지도학습 방식

- 머신러닝 : 데이터를 기반으로 패턴을 학습하고 예측을 수행하는 인공지능의 분야. 주어진 데이터를 사용하여 기능을 수행하고, 시간이 지남에 따라 그 기능이 점차적으로 향상됨. 머신러닝의 유형으로 지도학습, 비지도학습, 강화학습이 있음.
    - 지도학습 : 레이블이 지정된 데이터를 사용하여 모델을 훈련시키고, 예측을 수행
    - 비지도학습 : 레이블이 없는 데이터를 사용하여 데이터의 구조나 패턴을 찾음.
    - 강화학습 : 에이전트가 환경과 상호작용하면서 보상을 최대화하는 방향으로 학습
- 딥러닝 : 알고리즘을 계층으로 구성하여 자체적으로 배우고 똑똑한 결정을 내릴 수 있는 신경망을 통해 인공지능을 만드는 머신러닝의 한 종류.
- 머신러닝의 지도학습 방식 선택 이유 : ‘시간', '온도', '습도', '에어컨 ON/OFF' 상태가 포함되어 있음. 이 데이터는 구조화된 형태이며, 명확한 입력(온도, 습도)과 출력(에어컨 ON/OFF)이 정의되어 있어 지도 학습 방식이 적합함.

## 사용할 지도학습 알고리즘

1. 로지스틱 회귀
    - 개념 : 독립변수의 선형 결합을 이용하여 사건의 발생 가능성을 예측하는데 사용되는 기법. 에어컨ON/OFF와 같은 이진 분류문제에 널리 사용되는 알고리즘. 온도, 습도와 같은 연속적인 변수에 잘 작동함.
    - 선택이유 :
        - 데이터 유형에 적합 : 이진분류에 널리 사용되는 알고리즘이기 때문. 또한 종속변수와 독립변수가 선형관계에 있기 때문에 로지스틱 회귀 모델이 적합하다고 생각.
        → 산점도: 온도와 습도를 x축, 에어컨의 상태를 y축에 표시하여 데이터 포인트 간의 관계를 시각적으로 분석. 이진 결과를 가지는 y축에는 로지스틱 회귀의 적합성을 보기 위한 선형 경향성을 확인할 수 있다.(확인 예정)
        - 단순성과 해석 용이성 : 로지스틱 회귀는 비교적 간단하고 해석하기 쉬운 모델. 모델의 예측이 어떻게 이루어지는지 이해하기 쉬움. 현재 데이터가 그리 복합하지 않으므로 사용하기 적합하다고 판단.
2. 랜덤 포레스트
    - 개념 : 결정 트리의 앙상블 학습 방법으로, 여러 개의 결정 트리를 생성하고 그 결과를 평균 내어 최종 예측을 도출. 과적합을 방지하고 높은 정확도를 제공.(결정트리 : 관측값과 목푯값을 연결시켜주는 예측 모델로서 나무 모양으로 데이터를 분류). 결정 트리를 사용하여 과거 데이터의 패턴을 학습.
    - 선택이유 :
        - 높은 예측 정확도 : 여러개의 결정 트리를 결합하여 최종 예측을 수행하는데, 이때 개별 트리가 이상치나 노이즈에 영향을 받더라도 전체 모델의 성능에 미치는 영향이 줄어듦. 이진 분류 문제에 있어서 랜덤 포레스트는 데이터의 다양한 변동성을 포착하여 각 클래스를 효과적으로 구분할 수 있음.
        - 과적합 방지 : 기간이 짧고, 에어컨 ON은 에어컨을 킬 때만 특정되기 때문에 데이터가 많지 않음. 단일 결정트리는 과적합되기 쉽지만, 랜덤포레스트는 여러 트리의 결과를 결합함으로써 과적합 문제를 크게 줄임.
        - 특정 중요도 평가 : 랜덤 포레스트는 각 특성의 중요도를 평가할 수 있어 어떤 변수가 타깃변수(에어커 ON/OFF)에 가장 큰 영향을 미치는지 식별 가능. 이는 이진 분류 문제에서 특히 유용함.
3. XG 부스트
    - 개념 : 그라디언트 부스팅을 기반으로 하는 머신러닝 알고리즘. 그라디언트 부스팅이랑 여러개의 약한 학습기를 순차적으로 학습시켜 결합함으로써 강한 예측 모델을 만드는 방법. 여러 개의 결정 트리를 순차적으로 학습하기 떄문에 각 트리는 이전 트리의 오류를 보정하는 방식으로 학습함.
    - 선택이유 :
        - 랜덤포레스트 보다 높은 정확도 제공 : 랜덤포레스트는 각 트리를 독립적으로 만드는 알고리즘. 반면 부스팅은 순차적으로 트리를 만들어 이전 트리로부터 더 나은 트리를 만들어내는 알고리즘.
        - 과적합 방지. L1과 L2 규제를 포함하여 모델의 과적합을 방지하는 메커니즘이 내장되어 있음.(L1 (Lasso) 및 L2 (Ridge) 규제는 머신러단 모델의 과적합을 방지하고, 모델의 일반화 능력을 향상시키기 위해 사용되는 두 가지 주요 규제 기법)
        - 결측치 처리 : 결측치를 자동으로 처리할 수 있는 기능이 있음.

### 랜덤 포레스트 vs XG 부스트

- 랜덤 포레스트는 각 결정 트리를 훈련시킬 때 전체 데이터셋에서 무작위로 샘플을 추출하는 부트스트랩 방법을 사용. 각 트리가 다소 다른 데이터셋에서 학습되게 하여 과적합을 감소시킴. 무작위 특성 선택을 통해 모델의 분산을 줄임.
→ 데이터가 매우 크거나 변수가 많을 때 과적합을 효과적으로 방지 가능. 비교적 간단하게 적용가능하고, 기본 설정만으로도 과적합에 강함.
- XG 부스트는 강력한 규제와 순차적 부스팅을 통해 편향을 감소시킴. 또한 트리가 너무 깊어지지 않도록 가지치를 수행하여 모델이 너무 복잡해지는 것을 방지.
→ 변수 선택과 정규화가 중요할 때 좋음. 더 세밀한 파라미터 조정이 필요하지만, 적절히 튜닝하면 더 높은 성능을 얻을 수 있음.
- 시간적 여유가 된다면 두가지 다 시행해서 성능을 비교해보고자 함.
